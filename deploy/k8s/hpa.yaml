# Horizontal Pod Autoscaler configurations for GO-PRO application
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: go-pro-backend-hpa
  namespace: go-pro
  labels:
    app: go-pro-backend
    component: autoscaler
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: go-pro-backend
  minReplicas: 2
  maxReplicas: 10
  metrics:
  # CPU utilization
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  # Memory utilization
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  # Custom metrics (requires metrics server and custom metrics API)
  - type: Pods
    pods:
      metric:
        name: http_requests_per_second
      target:
        type: AverageValue
        averageValue: "100"
  # External metrics (requires external metrics API)
  - type: External
    external:
      metric:
        name: redis_connections
        selector:
          matchLabels:
            app: redis
      target:
        type: AverageValue
        averageValue: "50"
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
      - type: Pods
        value: 2
        periodSeconds: 60
      selectPolicy: Min
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
      - type: Pods
        value: 4
        periodSeconds: 60
      selectPolicy: Max

---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: go-pro-frontend-hpa
  namespace: go-pro
  labels:
    app: go-pro-frontend
    component: autoscaler
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: go-pro-frontend
  minReplicas: 2
  maxReplicas: 8
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 60
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 70
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 25
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 100
        periodSeconds: 60

---
# Vertical Pod Autoscaler for database (if VPA is installed)
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: postgres-vpa
  namespace: go-pro
  labels:
    app: postgres
    component: autoscaler
spec:
  targetRef:
    apiVersion: apps/v1
    kind: StatefulSet
    name: postgres
  updatePolicy:
    updateMode: "Auto"
  resourcePolicy:
    containerPolicies:
    - containerName: postgres
      minAllowed:
        cpu: 100m
        memory: 256Mi
      maxAllowed:
        cpu: 2
        memory: 4Gi
      controlledResources: ["cpu", "memory"]

---
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: redis-vpa
  namespace: go-pro
  labels:
    app: redis
    component: autoscaler
spec:
  targetRef:
    apiVersion: apps/v1
    kind: StatefulSet
    name: redis
  updatePolicy:
    updateMode: "Auto"
  resourcePolicy:
    containerPolicies:
    - containerName: redis
      minAllowed:
        cpu: 50m
        memory: 128Mi
      maxAllowed:
        cpu: 1
        memory: 2Gi
      controlledResources: ["cpu", "memory"]

---
# Pod Disruption Budget for backend
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: go-pro-backend-pdb
  namespace: go-pro
  labels:
    app: go-pro-backend
    component: disruption-budget
spec:
  minAvailable: 1
  selector:
    matchLabels:
      app: go-pro-backend

---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: go-pro-frontend-pdb
  namespace: go-pro
  labels:
    app: go-pro-frontend
    component: disruption-budget
spec:
  minAvailable: 1
  selector:
    matchLabels:
      app: go-pro-frontend

---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: postgres-pdb
  namespace: go-pro
  labels:
    app: postgres
    component: disruption-budget
spec:
  minAvailable: 1
  selector:
    matchLabels:
      app: postgres

---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: redis-pdb
  namespace: go-pro
  labels:
    app: redis
    component: disruption-budget
spec:
  minAvailable: 1
  selector:
    matchLabels:
      app: redis

---
# Custom Resource for KEDA (Kubernetes Event-driven Autoscaling) if installed
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: go-pro-backend-keda
  namespace: go-pro
  labels:
    app: go-pro-backend
    component: keda-autoscaler
spec:
  scaleTargetRef:
    name: go-pro-backend
  pollingInterval: 30
  cooldownPeriod: 300
  idleReplicaCount: 1
  minReplicaCount: 2
  maxReplicaCount: 20
  triggers:
  # Scale based on Kafka consumer lag
  - type: kafka
    metadata:
      bootstrapServers: kafka-service:9092
      consumerGroup: go-pro-backend
      topic: user.events
      lagThreshold: '10'
  # Scale based on Redis queue length
  - type: redis
    metadata:
      address: redis-service:6379
      listName: task_queue
      listLength: '5'
  # Scale based on Prometheus metrics
  - type: prometheus
    metadata:
      serverAddress: http://prometheus:9090
      metricName: http_requests_per_second
      threshold: '100'
      query: sum(rate(http_requests_total{job="go-pro-backend"}[1m]))

---
# KEDA ScaledObject for Kafka consumer
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: go-pro-kafka-consumer-keda
  namespace: go-pro
  labels:
    app: go-pro-kafka-consumer
    component: keda-autoscaler
spec:
  scaleTargetRef:
    name: go-pro-kafka-consumer
  pollingInterval: 15
  cooldownPeriod: 180
  idleReplicaCount: 0
  minReplicaCount: 1
  maxReplicaCount: 10
  triggers:
  - type: kafka
    metadata:
      bootstrapServers: kafka-service:9092
      consumerGroup: go-pro-consumer
      topic: course.events,progress.events,audit.events
      lagThreshold: '5'
      offsetResetPolicy: earliest

---
# Custom Metrics API configuration (if using custom metrics)
apiVersion: v1
kind: ConfigMap
metadata:
  name: adapter-config
  namespace: custom-metrics
data:
  config.yaml: |
    rules:
    - seriesQuery: 'http_requests_total{namespace!="",pod!=""}'
      resources:
        overrides:
          namespace: {resource: "namespace"}
          pod: {resource: "pod"}
      name:
        matches: "^http_requests_total"
        as: "http_requests_per_second"
      metricsQuery: 'sum(rate(<<.Series>>{<<.LabelMatchers>>}[1m])) by (<<.GroupBy>>)'
    - seriesQuery: 'redis_connected_clients{namespace!="",pod!=""}'
      resources:
        overrides:
          namespace: {resource: "namespace"}
          pod: {resource: "pod"}
      name:
        matches: "^redis_connected_clients"
        as: "redis_connections"
      metricsQuery: 'avg(<<.Series>>{<<.LabelMatchers>>}) by (<<.GroupBy>>)'

---
# ServiceMonitor for Prometheus Operator (if using Prometheus Operator)
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: go-pro-backend-metrics
  namespace: go-pro
  labels:
    app: go-pro-backend
    component: monitoring
spec:
  selector:
    matchLabels:
      app: go-pro-backend
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics
    honorLabels: true
  namespaceSelector:
    matchNames:
    - go-pro
